{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/boris/projects/aimasters/utils')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_contest.csv')\n",
    "test = pd.read_csv('data/test_contest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8',\n",
       "       'cat9',\n",
       "       ...\n",
       "       'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11',\n",
       "       'cont12', 'cont13', 'cont14'],\n",
       "      dtype='object', length=131)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расчет матрицы корреляций для 131 признаков...\n",
      "Матрица корреляций рассчитана.\n",
      "Матрица корреляций слишком велика для визуализации heatmap.\n",
      "\n",
      "Поиск сильно скоррелированных пар (абсолютное значение > 0.95)...\n",
      "Найдено 3 пар с корреляцией > 0.9:\n",
      "  - cont12 и cont11: 0.9944\n",
      "  - cat89 и cat7: 0.9586\n",
      "  - cat90 и cat3: 0.9572\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = train.select_dtypes('object').columns\n",
    "num_features = train.select_dtypes(np.number).columns\n",
    "features = train.columns.drop('target')\n",
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from  sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "ct = ColumnTransformer([\n",
    "    ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', encoded_missing_value=np.nan), cat_features),\n",
    "    ('num', StandardScaler(), num_features)\n",
    "])\n",
    "pipeline = Pipeline([\n",
    "    ('ct', ct)\n",
    "])\n",
    "# pipeline.fit(train)\n",
    "new_train = pd.DataFrame(enc.fit_transform(train[cat_features]))\n",
    "new_test = pd.DataFrame(enc.transform(test[cat_features]))\n",
    "new_train.columns = cat_features\n",
    "new_test.columns = cat_features\n",
    "numer = train[num_features]\n",
    "new_train = pd.concat([new_train, numer], axis=1)\n",
    "new_test = pd.concat([new_test, test[num_features[:-1]]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9',\n",
      "       'cat10',\n",
      "       ...\n",
      "       'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12',\n",
      "       'cont13', 'cont14', 'target'],\n",
      "      dtype='object', length=131)\n",
      "Index(['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8',\n",
      "       'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(new_train.columns)\n",
    "print(num_features[:-1])\n",
    "new_test['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80462, 131)\n",
      "(39632, 131)\n"
     ]
    }
   ],
   "source": [
    "tr_tr, tr_test = get_split(new_train)\n",
    "print(tr_tr.shape)\n",
    "print(tr_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9',\n",
      "       'cat10',\n",
      "       ...\n",
      "       'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12',\n",
      "       'cont13', 'cont14', 'target'],\n",
      "      dtype='object', length=131)\n"
     ]
    }
   ],
   "source": [
    "print(tr_tr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval_name-rmse:2845.05323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/.local/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [12:44:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"metric\", \"verbose\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tval_name-rmse:2433.10727\n",
      "[100]\tval_name-rmse:2228.60009\n",
      "[150]\tval_name-rmse:2120.49147\n",
      "[200]\tval_name-rmse:2059.49725\n",
      "[250]\tval_name-rmse:2020.01692\n",
      "[299]\tval_name-rmse:1993.26120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline = train_xgb_model(tr = tr_tr, val = tr_test, features=features, target_col='target', params= {'objective': 'reg:squarederror'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_no_corr = tr_tr.columns.drop('cat89')\n",
    "features_no_corr = features_no_corr.drop('cat90')\n",
    "features_no_corr = features_no_corr.drop('cont12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval_name-rmse:2829.00242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/.local/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [12:47:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"metric\", \"verbose\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tval_name-rmse:1730.18841\n",
      "[100]\tval_name-rmse:1075.86102\n",
      "[150]\tval_name-rmse:693.80686\n",
      "[200]\tval_name-rmse:483.85519\n",
      "[250]\tval_name-rmse:378.82773\n",
      "[299]\tval_name-rmse:333.72808\n"
     ]
    }
   ],
   "source": [
    "no_corr_baseline = train_xgb_model(tr = tr_tr, val = tr_test, features=features_no_corr, target_col='target', params= {'objective': 'reg:squarederror'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def gradient(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    '''Compute the gradient squared log error.'''\n",
    "    y = dtrain.get_label()\n",
    "    return (np.log1p(predt) - np.log1p(y)) / (predt + 1)\n",
    "\n",
    "def hessian(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    '''Compute the hessian for squared log error.'''\n",
    "    y = dtrain.get_label()\n",
    "    return ((-np.log1p(predt) + np.log1p(y) + 1) /\n",
    "            np.power(predt + 1, 2))\n",
    "\n",
    "def squared_log(predt: np.ndarray,\n",
    "                dtrain: xgb.DMatrix) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''Squared Log Error objective. A simplified version for RMSLE used as\n",
    "    objective function.\n",
    "    '''\n",
    "    predt[predt < -1] = -1 + 1e-6\n",
    "    grad = gradient(predt, dtrain)\n",
    "    hess = hessian(predt, dtrain)\n",
    "    return grad, hess\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
